{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b1842e",
   "metadata": {},
   "source": [
    "# Object Detection using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df0764",
   "metadata": {},
   "source": [
    "# 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f33035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91b530",
   "metadata": {},
   "source": [
    "# 2.Define the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25de104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset directory\n",
    "dataset_dir = \"C:\\\\Users\\\\saumy\\\\Downloads\\\\object detection\\\\Dataset\"\n",
    "\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['car', 'Bus', 'motor cycle', 'Truck', 'Auto', 'Tempo Traveller','Tractor']\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# Define the input image dimensions\n",
    "input_shape = (150, 150, 3)\n",
    "class_folders=os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7b9bf",
   "metadata": {},
   "source": [
    "# 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee97ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd5841",
   "metadata": {},
   "source": [
    "# 4. image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04fffbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize empty lists for storing the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "for class_label in class_labels:\n",
    "    if class_label in class_folders:\n",
    "        class_dir = os.path.join(dataset_dir, class_label)\n",
    "        for image_file in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, input_shape[:2])\n",
    "            image = image.astype('float32') / 255.0\n",
    "            images.append(image)\n",
    "            labels.append(class_labels.index(class_label))\n",
    "    else:\n",
    "        print(f\"Folder not found for class label: {class_label}\")\n",
    "\n",
    "# Convert the images and labels to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "labels = np.eye(num_classes)[labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f721a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% for training, 20% for testing)\n",
    "split = int(0.8 * len(images))\n",
    "train_images, test_images = images[:split], images[split:]\n",
    "train_labels, test_labels = labels[:split], labels[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859530d",
   "metadata": {},
   "source": [
    "# 5. Train the model and find the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462661da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 24s 491ms/step - loss: 0.6654 - accuracy: 0.7541\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 28s 598ms/step - loss: 0.3923 - accuracy: 0.8520\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 27s 575ms/step - loss: 0.3156 - accuracy: 0.8764\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 27s 581ms/step - loss: 0.2441 - accuracy: 0.8953\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 26s 562ms/step - loss: 0.2022 - accuracy: 0.9203\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 27s 575ms/step - loss: 0.1427 - accuracy: 0.9432\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 27s 579ms/step - loss: 0.1052 - accuracy: 0.9608\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 27s 582ms/step - loss: 0.0607 - accuracy: 0.9811\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 27s 576ms/step - loss: 0.0960 - accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 27s 575ms/step - loss: 0.0767 - accuracy: 0.9723\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 16.3323 - accuracy: 0.0027\n",
      "Test Loss: 16.332273483276367\n",
      "Test Accuracy: 0.0027027027681469917\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449b34e",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "This code implements a CNN using Keras and OpenCV for image classification. It loads and preprocesses images from a dataset directory, splits them into training and testing sets, and builds a CNN model. The model is trained on the training set and evaluated on the testing set. The code provides the test loss and accuracy as the evaluation metrics. It serves as a basic example for image classification using a CNN with Keras and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a766b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
